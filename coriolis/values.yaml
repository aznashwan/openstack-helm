
# List of provider plugins to enable/include:
# TODO: unused yet, everything is hardcoded as enabled.
providers:
  source:
    - aws
    - azure
    - openstack
    - opc
    - oracle_vm
    - vmware_vsphere
  destination:
    - aws
    - azure
    - oci
    - opc
    - oracle_vm
    - openstack
    - scvmm

# Labels used by openstack-helm:
labels:
  api:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  conductor:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  replica_cron:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  worker:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  web:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  web-proxy:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  job:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled

release_group: null

images:
  tags:
     # TODO: check if these images are compatible:
    bootstrap: docker.io/openstackhelm/heat:stein-ubuntu_bionic
    db_init: docker.io/openstackhelm/heat:stein-ubuntu_bionic
    db_drop: docker.io/openstackhelm/heat:stein-ubuntu_bionic
    dep_check: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
    # NOTE: db sync will be performed by the conductor on startup
    rabbit_init: docker.io/rabbitmq:3.7-management
    ks_user: docker.io/openstackhelm/heat:stein-ubuntu_bionic
    ks_service: docker.io/openstackhelm/heat:stein-ubuntu_bionic
    ks_endpoints: docker.io/openstackhelm/heat:stein-ubuntu_bionic
    coriolis_db_sync: registry.cloudbase.it/appliance/coriolis-conductor:latest
    coriolis_api: registry.cloudbase.it/appliance/coriolis-api:latest
    coriolis_conductor: registry.cloudbase.it/appliance/coriolis-conductor:latest
    coriolis_replica_cron: registry.cloudbase.it/appliance/coriolis-replica-cron:latest
    coriolis_worker: registry.cloudbase.it/appliance/coriolis-worker:latest
    coriolis_web: registry.cloudbase.it/appliance/coriolis-web:latest
    coriolis_web_proxy: registry.cloudbase.it/appliance/coriolis-web-proxy:latest
  pull_policy: "IfNotPresent"
  imageCredentials:
    coriolisImagePullSecret: cbslreg
  local_registry:
    active: false
    exclude:
      - dep_check
      - image_repo_sync

pod:
  security_context:
    coriolis_api:
      pod:
        runAsUser: 42424
      container:
        coriolis_api:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          runAsUser: 0
    coriolis_conductor:
      pod:
        runAsUser: 42424
      container:
        coriolis_conductor:
          redOnlyRootFilesystem: true
          runAsUser: 0
    coriolis_replica_cron:
      pod:
        runAsUser: 42424
      container:
        coriolis_replica_cron:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          runAsUser: 0
    coriolis_worker:
      pod:
        runAsUser: 42424
      container:
        # TODO: do init stuff like downloading/setting vixDiskLib
        init_coriolis_conf:
          runAsUser: 0
          readOnlyRootFilesystem: true
        coriolis_worker:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          runAsUser: 0
        # TODO:
        # - define check/create/mount external bin dir
    coriolis_web:
      pod:
        runAsUser: 42424
      container:
        # TODO: define:
        init_coriolis_web_conf:
          runAsUser: 0
          readOnlyRootFilesystem: true
        coriolis_web:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          runAsUser: 0
    coriolis_web_proxy:
        # TODO: define:
        init_coriolis_web_proxy_conf:
          runAsUser: 0
          readOnlyRootFilesystem: true
        coriolis_web_proxy:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          runAsUser: 0

  affinity:
    anti:
      type:
        default: preferredDuringSchedulingIgnoredDuringExecution
      topologyKey:
        default: kubernetes.io/hostname
      weight:
        default: 10

  mounts:
    # NOTE: used to specify any additional desired mounts
    # The standard mounts (ex: /etc and binary files) are handled
    # in the templates automatically:
    coriolis_api:
      init_container: null
      coriolis_api:
        volumeMounts:
        volumes:
    coriolis_conductor:
      init_container: null
      coriolis_conductor:
        volumeMounts:
        volumes:
    coriolis_replica_cron:
      init_container: null
      coriolis_replica_cron:
        volumeMounts:
        volumes:
    coriolis_worker:
      init_container: null
      coriolis_worker:
        volumeMounts:
        volumes:
    coriolis_web:
      init_container: null
      coriolis_web:
        volumeMounts:
        volumes:
    coriolis_web_proxy:
      init_container: null
      coriolis_web_proxy:
        volumeMounts:
        volumes:
    coriolis_db_sync:
      init_container: null
      coriolis_db_sync:
        volumeMounts:
        volumes:

  replicas:
    api: 1
    conductor: 1
    replica_cron: 1
    worker: 1
    web: 1
    web_proxy: 1

  lifecycle:
    upgrades:
      deployments:
        # NOTE: useful when upgrading the chart:
        revision_history: 1
        pod_replacement_strategy: RollingUpdate
        rolling_update:
          max_unavailable: 1
          max_surge: 3
    disruption_budget:
      api:
        min_available: 0
    termination_grace_period:
      api:
        timeout: 30

  resources:
    # TODO: try enabling to see how it works:
    enabled: false
    api:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
    conductor:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
    replica_cron:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
    worker:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
    web:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
    web-proxy:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
    jobs:
      # TODO: check jobs list:
      bootstrap:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      clean:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      create_internal_tenant:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      db_init:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      db_sync:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      db_drop:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      ks_endpoints:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      ks_service:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      ks_user:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"
      rabbit_init:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "1024Mi"
          cpu: "2000m"

bootstrap:
  enabled: true
  ks_user: admin
  # TODO: add functionalities such as pre-creating endpoints and such here

network:
  api:
    ingress:
      public: true
      classes:
        namespace: "nginx"
        cluster: "nginx-cluster"
      annotations:
        nginx.ingress.kubernetes.io/rewrite-target: /
    external_policy_local: false
    node_port:
      enabled: false
      port: 30667

conf:
  paste:
    composite:coriolis-api:
      use: call:coriolis.api:root_app_factory
      /v1: coriolis-api-v1
    pipeline:coriolis-api-v1:
      pipeline: request_id faultwrap authtoken keystonecontext apiv1
    app:apiv1:
      paste.app_factory: coriolis.api.v1.router:APIRouter.factory
    filter:authtoken:
      paste.filter_factory: keystonemiddleware.auth_token:filter_factory
    filter:faultwrap:
      paste.filter_factory: coriolis.api.middleware.fault:FaultWrapper.factory
    filter:keystonecontext:
      paste.filter_factory: coriolis.api.middleware.auth:CoriolisKeystoneContext.factory
    filter:request_id:
      paste.filter_factory: oslo_middleware.request_id:RequestId.factory
  policy:
    admin: "role:admin"
    admin_or_owner: "rule:admin or project_id:%(project_id)s"

    migration:providers:list: "rule:admin_or_owner"

    migration:endpoints:create: "rule:admin_or_owner"
    migration:endpoints:list: "rule:admin_or_owner"
    migration:endpoints:show: "rule:admin_or_owner"
    migration:endpoints:update: "rule:admin_or_owner"
    migration:endpoints:delete: "rule:admin_or_owner"
    migration:endpoints:validate_connection: "rule:admin_or_owner"
    migration:endpoints:list_instances: "rule:admin_or_owner"
    migration:endpoints:get_instance: "rule:admin_or_owner"
    migration:endpoints:list_networks: "rule:admin_or_owner"
    migration:endpoints:list_source_options: "rule:admin_or_owner"
    migration:endpoints:list_destination_options: "rule:admin_or_owner"

    migration:migrations:create: "rule:admin_or_owner"
    migration:migrations:list: "rule:admin_or_owner"
    migration:migrations:show: "rule:admin_or_owner"
    migration:migrations:show_execution: "rule:admin_or_owner"
    migration:migrations:cancel: "rule:admin_or_owner"
    migration:migrations:delete: "rule:admin_or_owner"

    migration:replicas:create: "rule:admin_or_owner"
    migration:replicas:list: "rule:admin_or_owner"
    migration:replicas:show: "rule:admin_or_owner"
    migration:replicas:show_executions: "rule:admin_or_owner"
    migration:replicas:delete_disks: "rule:admin_or_owner"
    migration:replicas:delete: "rule:admin_or_owner"

    migration:replica_executions:create: "rule:admin_or_owner"
    migration:replica_executions:list: "rule:admin_or_owner"
    migration:replica_executions:show: "rule:admin_or_owner"
    migration:replica_executions:cancel: "rule:admin_or_owner"
    migration:replica_executions:delete: "rule:admin_or_owner"

    migration:replica_schedules:create: "rule:admin_or_owner"
    migration:replica_schedules:list: "rule:admin_or_owner"
    migration:replica_schedules:show: "rule:admin_or_owner"
    migration:replica_schedules:update: "rule:admin_or_owner"
    migration:replica_schedules:delete: "rule:admin_or_owner"
  coriolis:
    DEFAULT:
      # NOTE: will be set by openstack-helm:
      providers:
      transport_url:
      messaging_transport_url:
      default_messaging_timeout: 60

      debug: true
      # TODO: abstract logging better:
      log_dir: /var/log/coriolis/
      log_config_append: /etc/coriolis/logging.conf
      logging_exception_prefix: "%(asctime)s.%(msecs)03d TRACE %(name)s %(instance)s"
      logging_debug_format_suffix: "from (pid=%(process)d) %(funcName)s %(pathname)s:%(lineno)d"
      logging_default_format_string: "%(asctime)s.%(msecs)03d %(levelname)s %(name)s [-] %(instance)s%(message)s"
      logging_context_format_string: "%(asctime)s.%(msecs)03d %(levelname)s %(name)s [%(request_id)s] %(instance)s%(message)s"

      include_task_info_in_migrations_api: false
      include_task_info_in_replicas_api: false
      include_task_info_in_replica_executions_api: false

      caching: true
      cache_time: 86400
      use_syslog: yes
      syslog_log_facility: LOG_LOCAL0

      internal_project_name: internal_coriolis
      internal_user_name: internal_coriolis

    cache:
      # TODO: enable caching
      enabled: false
      backend: dogpile.cache.memcached
      backend_argument: url:localhost:11211

    database:
      # NOTE: to be set by openstack-helm:
      connection:
      max_retries: -1

    keystone_authtoken:
      # NOTE: all the other required params will be set in the configmap-etc job:
      auth_version: v3
      auth_type: password
      memcache_security_strategy: ENCRYPT
    oslo_concurrency:
      lock_path: "/var/lib/coriolis/tmp"
    oslo_messaging_notifications:
      driver: messagingv2
    trustee:
      # TODO:
    keystone:
      # TODO:
    oslo_policy:
      # TODO: avoid hardcoding this:
      policy_file = /etc/coriolis/policy.json
    conductor:
      debug_os_morphing_errors: false
      conductor_rpc_timeout: 60
    worker:
      worker_rpc_timeout: 60

  providers:
    provider_conf_file_mount_dir: "/etc/coriolis/providers"
    provider_conf_file_name_format: "%s-migration-provider.conf"
    aws: |
      [aws_migration_provider]
      # The OS migration image map to use. This mapping will be used to spin up
      # the disk export worker needed to replicate the export disks and OS morphing
      # worker needed to morph the OS being migrated.
      # migr_image_map = linux: ami-50946030, windows: ami-50946031
      
      # A map similar with migr_image_map, where we specify the username for each OS
      # image. On EC2, various linux distributions, have different usernames.
      # Default is 'ubuntu' for Linux and 'coriolis' for Windows.
      # migr_image_username_map = linux: ubuntu, windows: coriolis
      
      # Name of the instance type to be used for the disk copy workers.
      # Default is t2.medium.
      worker_instance_type = t2.medium
      
      # Indicate whether or not to shut the VM down during the
      # migration process in order to ensure data consitency.
      shutdown_migrated_instance = False
      
      # Default instance type used for final migrated instances.
      # instance_type = t2.medium
      
      # Whether or not to attempt to retain the IP addresses the VM had on the
      # source. This requires that the mapped subnets on AWS include the respective
      # IP address(es) in their ranges.
      # Default is False.
      retain_source_ip = false
      
      # The storage type to default to for the disks of Migrated VMs if an explicit
      # storage mapping was not supplied during the Replica/Migration creation.
      # Default is 'standard'
      default_storage_type = standard
      
      # Default AD to use when creating resources for Migrated/Replicated VMs.
      # Must be in the same region as specified within the connection info.
      # availability_zone = az1
    
    azure: |
      [azure_migration_provider]
      ### Export parameters:
      
      # The Azure location to use for any temporary export resources.
      # Under most circumstances, this should be the same as the location of the VM
      # being Migrated/Replicated which should be specified in the source-env.
      export_location = westus
      
      # Default Migration worker VM size. This will be used if no worker_size is set in
      # the source_environment. If none is provided, Coriolis will list all available
      # flavors on Azure and select the smallest available one that can accommodate
      # the number of disks. If not given, Coriolis will select the first worker
      # size available which can accomodate attaching all the disks for the
      # particular VM being migrated/replicated.
      export_worker_size = Standard_D1
      
      # Params of the Azure image to use for the temporary VM:
      export_worker_image = version: latest, publisher: Canonical, offer: UbuntuServer, sku: 18.04-LTS
      
      # For use with AzureStack, the following ARM Provider API versions must be
      # configured to API versions supported by the AzureStack. If unset, they will
      # default to the latest API versions which are supported by the ARM client
      # libraries bundled with Coriolis.
      # export_arm_resource_api_version = 2016-09-01
      # export_arm_compute_api_version = 2016-03-30
      # export_arm_network_api_version = 2015-06-15
      # export_blob_storage_api_version = 2015-04-05
      
      ### Import parameters:
      
      # The Azure location to which to migrate. The location may also be set for each
      # migration/replica in turn using the destination-environment paramter.
      migr_location = westus
      
      # Name of the Azure storage account to create VHD Page blobs on if
      # "disk_storage_backing_type" is set to "blob_storage"
      # storage_account_name = storageaccount
      
      # Name of the Azure storage container to create VHD page blobs on if
      # "disk_storage_backing_type" is set to 'blob_storage'
      # storage_container_name = coriolis
      
      # The type of storage backing to use for the disks of VMs migrated to Azure.
      # If set to 'blob_storage', disks will be transferred as VHD Page Blobs inside
      # a pre-existing Blob Storage Account inside the resource group being migrated
      # to. If set to 'managed_disks', disks will be transferred as Managed Disks
      # within the resource group being migrated to. If not set, Coriolis will query
      # the available Compute API versions to determine if Managed Disks are
      # available (2017-03-30 onwards), else it defaults to using Blob Storage.
      disk_storage_backing_type = managed_disks
      
      # Default migrated instance size. This will be used if no vm_size is set in
      # the destination-environment. Note: migration will fail if migrated instance
      # size cannot accommodate the number of disks than can be migrated.
      # If not set, the smallest available size that can accommodate the number of
      # disks will be selected for the VM.
      # default_vm_size = Standard_A1
      
      # The images to use for temporary worker VMs:
      linux_migr_image = version: latest, publisher: Canonical, offer: UbuntuServer, sku: 18.04-LTS
      windows_migr_image = version: latest, publisher: MicrosoftWindowsServer, offer: WindowsServer, sku: 2016-Datacenter-Server-Core
      
      # Default migration worker size. This will be used if no worker_size is set in
      # the target_environment. If none is provided, Coriolis will list all available
      # flavors on Azure and select the smallest available one that can accommodate
      # the number of disks. If not given, Coriolis will select the first worker
      # size available which can accomodate attaching all the disks for the
      # particular VM being migrated/replicated.
      default_worker_size = Standard_D1
      
      # Whether or not to set any IP addresses read from source VM NIC configurations
      # to destination NICs on Azure. This requires that the network/subnet mappings
      # in the 'network_map' are to networks/subnets on Azure which include the range
      # of the source networks. Default is True
      preserve_nic_ips = True
      
      # For use with AzureStack, the following ARM Provider API versions must be
      # configured to API versions supported by the AzureStack. If unset, they will
      # default to the latest API versions which are supported by the ARM client
      # libraries bundled with Coriolis.
      # arm_resource_api_version = 2016-09-01
      # arm_compute_api_version = 2016-03-30
      # arm_network_api_version = 2015-06-15
      # blob_storage_api_version = 2015-04-05
      # arm_storage_api_version = 2018-07-01
      
      # Cloudbase-init Zip URLs for each supported Windows architecture:
      cloudbaseinit_x86_url = https://www.cloudbase.it/downloads/CloudbaseInitSetup_x86.zip
      cloudbaseinit_x64_url = https://www.cloudbase.it/downloads/CloudbaseInitSetup_x64.zip
    
    oci: |
      [oci_migration_provider]
      # You need to configure this to match your situation
      # there is no sensible default that can work globally. The images
      # are specific to the region you are in. The bellow ones are from
      # us-phoenix-1
      # migr_image_map = linux: ocid1.image.oc1.phx.aaaaaaaatel6prh7kwlb77zp6m4v523pegz3fh2j5ulq2lwtmhionpy37wkq, windows: ocid1.image.oc1.phx.aaaaaaaam3rbuegojxzdomvbp6qa2fb45ex24ng7c5ykawuqmomerfblveaq
      
      # Whether to use paravirtualized mode by default for
      # instances that use BIOS.
      default_to_pv_mode = true
      
      # Default shape name used for final instances
      shape_name = VM.Standard1.2
      
      # Default shape name used for worker instances
      # during migrations.
      migr_shape_name = VM.Standard1.2
      
      # Default network name used for worker instances
      # during migrations.
      # migr_subnet_id =
      
      # Default compartment in which the migration should take place.
      # compartment =
      
      # Whether or not to set Public IPs on the Migrated/Replicated VMs:
      set_public_ip = True
      
      # Default attach type to be used when attaching secondary
      # disks to the migrated instance. Accepted values:
      # 'iscsi', 'emulated', 'paravirtualized'
      default_attach_type = iscsi
      
      # Windows VMs that are migrated to OCI need virtio drivers.
      # The steps to downloading GA drivers can be found at:
      # https://blogs.oracle.com/linux/announcing-oracle-virtio-drivers-113-for-microsoft-windows
      # The downloaded ZIP has to be self-hosted. Pass the ZIP URL to the option below:
      # windows_virtio_zip_url = https://example.com/virtio-1.1.3.zip
    
    opc: |
      [opc_migration_provider]
      # Linux and Windows images for the temporary Worker VMs:
      # migr_image_name_map = linux: /oracle/public/OL_7.5_UEKR4_x86_64_MIGRATION, windows: /Compute-a488347/gsamfira@cloudbasesolutions.com/Windows_2012_R2
      migr_image_map = linux: /oracle/public/OL_7.5_UEKR4_x86_64_MIGRATION
      
      # The shape to use for the migration Worker VMs:
      migr_shape_name = oc3
      
      # Default volume pool to use. Oracle exposes 2 pools: "default" and "latency".
      # The default pool leverages rotary disks, while the latency disks are backed
      # by SSD and low latency storage subsystem. The latency pool is suitable for
      # databases.
      default_volume_pool = /oracle/public/storage/default
      
      # Default network name used for worker instances
      # during migrations.
      # migr_network_name = /Compute-a514847/default
      
      # URL of a zip file with the Windows PV drivers:
      windows_pv_drivers_url = https://cloudbase.it/downloads/app/ovm/ovm_win_pv_drivers_all_323_bare_root.zip
      
      # Image used for the export worker
      export_image_name = /oracle/public/OL_7.2_UEKR4_x86_64
      
      # Shape used for export worker
      export_shape_name = oc3
      
      # Exporting an instance may require an extra disk to be attached, to accomodate the size of the
      # largest disks that belong to the exported instance. Make sure to allocate enough space here.
      export_root_disk_size = 150
      
      # Default shape name used for migrated instances.
      shape_name = oc3
      
      # Admin username for the export_image_name. Default username is 'opc'.
      # export_img_username =
    
    openstack: |
      [openstack_migration_provider]
      ### Export parameters:
      
      # Integer version of the Image API to use for any interactions with Glance,
      # supported versions being 1 and 2.
      # This value may be overriden on a per-cloud basis with the 'glance_api_version'
      # parameter in the endpoint connection info.
      # Default is 1
      glance_api_version = 1
      
      # Whether to skip certificate verification if the Swift proxy is HTTPS-only
      # with self-signed certificates.
      # This value may be overriden on a per-cloud basis with the
      # 'allow_untrusted_swift' parameter in the connection info.
      # Default is False
      allow_untrusted_swift = False
      
      # Custom mapping between the 'os_type' or 'os_distro' of Glance images on the
      # source OpenStack. Mapping values must be one of the supported OS types in
      # Coriolis. ('linux', 'windows', or 'solaris')
      # custom_os_type_map =
      
      # What Cinder implementation to leverage during replica exports.
      # If set to 'swift_backups', Coriolis will create Cinder backups for each
      # replicated VM disk and fetch the backup objects from Swift.
      # If set to 'ceph_backups', Coriolis will create Cinder backups and connect
      # to the source OpenStack's Ceph via RADOS to retrieve the chunks of each disk.
      # If set to 'ceph_snapshots', Coriolis will create Cinder snapshots for each disk
      # and fetch the diff chunks from the source OpenStack's Ceph.
      # Both the 'ceph_backups' and 'ceph_snapshots' options require that the
      # coriolis-worker component have network access to the source OpenStack's Ceph
      # through librbd/librados.
      # If set to 'coriolis_backups', Coriolis will create a temporary VM on the source
      # and use its in-built Replication engine through it to diff/export the disks.
      # Only the 'coriolis_backups' mechanism works for VMs which were booted from a
      # Glance image, and all other options only work on Cinder-based VMs.
      # Default is 'swift_backups'
      replica_export_mechanism = swift_backups
      
      ## Options for 'replica_export_mechanism = swift_backups'
      
      # The name of the Swift container in which to store the Cinder backups.
      # If pre-existing, the container will be reused. If it doesn't exist, a new one
      # will be created.
      # Default is 'coriolis'
      volume_backups_container = coriolis
      
      ## Options for 'replica_export_mechanism = ceph_backups/snapshots'
      
      # Integer timeout (seconds) when connecting to Ceph.
      # Default is 30
      cinder_ceph_timeout = 30
      
      # String name of algorith in Python's hashlib to use for hashing disk chunks to
      # compare them. If unset, the diff will be compared directly instead of hashing.
      # cinder_ceph_backups_diff_hash_algorithm = None
      
      ## Options for 'replica_export_mechanism = coriolis_backups'
      
      # Name or ID of a pre-existing Glance Ubuntu 18.04 image on the source OpenStack
      # to be used for the temporary export worker VM on the source. The image must be
      # available to the project/tenant provided in the Coriolis Endpoint. The images
      # must have cloud-init installed and configured for first boot.
      # export_image = ubuntu-18.04-coriolis-worker
      
      # Name of pre-existing Cinder volume type on the source to use for the temporary
      # volumes Coriolis will be creating for exporting instance Glance images. In the
      # case of secondary volumes, the storage type already used by the individual
      # volumes will be used to avoid a cross-backend volume transfer while the clone
      # is occurring. If unset, the default Cinder volume type will be used.
      # export_interim_volume_type = 
      
      # Whether or not to download the worker image to a Cinder volume and boot the
      # worker from that. The root disk size" on the configured 'export_flavor_name'
      # will be used for the worker VM volume.
      export_worker_boot_from_volume = false
      
      # Name of the precreated Cinder volume type to use when creating temporary worker volumes.
      # This option is only effective if "export_worker_boot_from_volume" is set.
      # export_worker_volume_type = cinder-volume-type
      
      # The integer size (in GBs) of the Cinder volume to boot temporary worker VMs from.
      # This option is only effective if "export_worker_boot_from_volume" is set. If not set,
      # Coriolis will use the disk size set the selected "export_flavor_name".
      # export_worker_volume_size = 100
      
      # Name of the flavor to use for the temporary disk export VM.
      # The flavor must be compatible with the selected 'export_image'.
      # export_flavor_name = m1.small
      
      # Name or ID of an existing Neutron network on the source OpenStack where to attach
      # the Neutron port of the temporary disk export worker VMs. The selected network
      # must either be in the same project/tenant as set in the Coriolis endpoint or
      # be a shared/external network and thus available to said project. If
      # export_worker_use_fip is set to 'false', the Coriolis installation must be
      # able to route to addresses allocated from this network."
      # export_network = external-network-name
      
      # Whether or not to allocate floating IPs from 'export_fip_pool_name' for the
      # temporary disk export worker VMs.
      # Default is true
      # export_worker_use_fip = true
      
      # Name of an external Neutron network from which to allocate floating IPs for the
      # temporary worker VMs Coriolis boots up during the disk export process. The
      # Coriolis installation must be able to route to addresses allocated from this network.
      # export_fip_pool_name = external
      
      # Whether or not to use config drive to send metadata to the temporary disk disk
      # export worker VMs in case Neutron metadata is not available. Default is false.
      # export_worker_use_config_drive = false
      
      ### Import parameters:
      
      # If migrating/replicating a heterogeneous workload with both Linux and
      # Windows instances, separate image names or IDs will need to be provided
      # for the temporary OSMorphing workers for each OS type.
      # The 'linux' image will be used for the disk copy worker during the replica
      # execution process as well
      # Only accepted keys are 'linux' and 'windows'
      # migr_image_map = linux: 283bdce4-112c-4758-b06a-7e5985a9cd15, windows: Windows Server 2012 R2 Std Eval
      
      # Boolean flag indicating whether or not to list all Neutron networks.
      # By default, Coriolis will only list the networks which are in the
      # same tenant as the one set in the Coriolis endpoint in use.
      list_all_destination_networks = False
      
      # Whether or not unallocated blocks on Cinder target volumes contain
      # zeros. This is controlled by the "volume_clear" Cinder configuration
      # options. (boolean value)
      volumes_are_zeroed = True
      
      # Default hypervisor type. (string value)
      # The type of hypervisor the destination OpenStack features,
      # supported options being "hyperv", "qemu" or "kvm"
      # Default is None, meaning no extra hypervisor-specific actions will be taken
      # during the OSMorphing process
      hypervisor_type = kvm
      
      # Whether or not to download the worker image to a Cinder volume and boot the
      # worker from that. The root disk size on the configured 'migr_flavor_name'
      # will be used for the worker VM volume, 'migr_flavor_name' will be used for
      # the worker VM volume unless explicitly specified using 'migr_worker_volume_size'.
      migr_worker_boot_from_volume = False
      
      # The integer size (in GBs) of the Cinder volume to boot temporary worker VMs
      # from. This option is only effective if "migr_worker_boot_from_volume" is set.
      # If not set, Coriolis will use the disk size set the selected "migr_flavor_name".
      # migr_worker_volume_size =
      
      # Name of the precreated Cinder volume type to use when creating temporary worker volumes.
      # This option is only effective if "migr_worker_boot_from_volume" is set.
      # migr_worker_volume_type =
      
      # Name of the Cinder volume type to be used for
      # volumes with unspecified storage backing option from the
      # source or which could not be mapped in the "storage_map".
      # Default is "" (Cinder scheduler will
      # use default volume type)
      # default_cinder_volume_type =
      
      # Whether or not to set the Cinder volumes as ephemeral (to be deleted when
      # the VM is deleted) on the newly migrated/replicated instance on the
      # destination OpenStack. Default is False.
      delete_disks_on_vm_termination = True
      
      # List of names or IDs of pre-existing security groups on the destination
      # OpenStack to be applied to the migrated/replicated instance.
      # Note that the below set will be joined with the list specified via the
      # 'security_groups' parameter from the set of destination environment parameters
      # (list value)
      # default_security_groups = secgroup1, secgroup2
      
      # Name or ID of an existing Neutron network on the destination
      # OpenStack where to attach the Neutron port of the temporary disk
      # copy/OSMorphing worker VMs. (string value)
      # migr_network = private
      
      # Whether or not to allocate floating IPs from the "migr_fip_pool_name"
      # for the temporary disk copy/OSMorphing worker VMs.
      # Default is True
      migr_worker_use_fip = True
      
      # Name of an existing Neutron network on the destination OpenStack which
      # serves as external and may have floating IPs allocated from it.
      # These floating IPs will be associated to the temporary disk copy/OSMorphing
      # worker VMs.
      # Default is "public"
      # migr_fip_pool_name = public
      
      # Name of an existing Nova flavor which to boot the temporary
      # disk copy/OSMorphing worker VMs as.
      # Default is "m1.small"
      # (string value)
      # migr_flavor_name = m1.small
      
      # Whether or not to use config drive to send metadata to the temporary
      # disk copy/OSMorphing worker VMs in case Neutron metadata is not available
      # Default is False
      migr_worker_use_config_drive = False
      
      # Whether or not to reconfigure the internal network settings of each
      # interface of the instance being migrated/replicated during the OSMorphing
      # process to have the VM perform DHCP on first boot inside the new environment.
      # Default is True
      set_dhcp = True
      
      # If set to "reuse_ports", Coriolis will reuse any Neutron ports found with
      # the MAC addresses needed for the new VM. If set to "keep_mac", Coriolis
      # will delete any ports with the MAC addresses the VM needs and recreate them
      # with the same MAC address. If set to "create_new_ports", Coriolis will always
      # create new ports with new MAC addresses.
      port_reuse_policy = keep_mac
      
      # Dictionary with arbitrary key-value pairs to set as tags on the
      # migrated/replicated VMs.
      # instance_tags =
      
      # Whether or not to preserve the fixed IPs of the migrated instances' Neutron
      # ports. When this is set to 'True', the target Openstack cloud will attempt
      # to create ports containing fixed IPs collected from the source VM. A subnet
      # with the right CIDR is required in the mapped network for the VM's first NIC.
      preserve_fixed_ips = False
      
      # Whether or not to attach a floating IP to the already migrated VM. This
      # option must be set to 'True' if the migrated VM is intended to have a public
      # IP attached. The floating IP will be allocated from the 'floating_ip_pool'
      # option.
      use_floating_ip = False
      
      # Name of the floating IP pool to be used for the creation and attachment of
      # floating IPs to the migrated VMs.
      # floating_ip_pool = public
      
      # Name or ID of the Nove Server Group to use when recreating the final VMs on Openstack
      # server_group =
      
      # Parameters realted to the OSMorphing process for Windows instances:
      windows_virtio_iso_url = https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/stable-virtio/virtio-win.iso
      cloudbaseinit_x64_url = https://www.cloudbase.it/downloads/CloudbaseInitSetup_x64.zip
      cloudbaseinit_x86_url = https://www.cloudbase.it/downloads/CloudbaseInitSetup_x86.zip
    
    oracle_vm: |
      [oracle_vm_migration_provider]
      # If migrating/replicating a heterogeneous workload with both Linux and
      # Windows instances, separate template names or IDs will need to be provided
      # # for the temporary OSMorphing workers for each OS type.
      # The 'linux' image will be used for the disk copy worker during the replica
      # execution process as well
      # Only accepted keys are 'linux' and 'windows'
      # migr_template_map = linux: OracleLinux7_template, windows: WS2016_template
      
      # Default migration template guest OS username.
      # migr_template_username_map = linux: root, windows: Administrator
      
      # Default migration template guest OS password.
      # migr_template_password_map = linux: Passw0rd, windows: Passw0rd
      
      # Default network name used for worker instances
      # during migrations.
      # migr_network_name = management
      
      # Default server pool name.
      # server_pool_name = pool1
      
      # Default repository name.
      # repository_name = repo1
      
      # Whether or not to just create VMs but skip powering them on.
      leave_migrated_vm_off = False
      
      # XEN VM domain type.
      # can be 'XEN_PVM', 'XEN_HVM', 'XEN_HVM_PV_DRIVERS', 'LDOMS_PVM', 'UNKNOWN'
      vm_domain_type = XEN_HVM_PV_DRIVERS
      
      # virtual_disk_clone_type can be: THIN_CLONE, SPARSE_COPY, NON_SPARSE_COPY
      virtual_disk_clone_type = THIN_CLONE
      
      # Location of the Cloudbase-Init ZIP for each supported architecture.
      # Cloudbase-Init is installed in Windows VMs for some of the auxiliary
      # functionality it offers to the migrated VMs (most notably, startup scripts)
      cloudbaseinit_x86_url = https://www.cloudbase.it/downloads/CloudbaseInitSetup_x86.zip
      cloudbaseinit_x64_url = https://www.cloudbase.it/downloads/CloudbaseInitSetup_x64.zip
      
      windows_pv_drivers_url = https://cloudbase.it/downloads/app/ovm/ovm_win_pv_drivers_all_323_bare_root.zip
      
      # For export we may need to use a different template than the linux one
      # specified in the template map, though in most cases the same one should work.
      # We specify that here (either by name or ID) with its credentials
      # export_template = OracleLinux7_template
      # export_template_username = root
      # export_template_password = Passw0rd
    
    scvmm: |
      [scvmm_migration_provider]
      ### Export parameters:
      
      # Attempt application consistent snapshots, and if that fails, fallback to
      # crash consistent snapshots.
      fallback_to_crash_consistent_snapshots = True
      
      # Verify the SSL certificate of the RTC service.
      # Set this to False if using a self signed certificate.
      verify_rct_server = False
      
      ### Import parameters:
      
      # Default vm templates used for worker instances during migrations
      # migr_template_name_map =
      
      # Default migration template guest OS username.
      # migr_template_username_map =
      
      # Cloud name, used for scheduling VMs.
      # cloud_name =
    
    vmware_vsphere: |
      [vmware_vsphere_migration_provider]
      # Required in order to set the compatibility of the vixDiskLib release
      # Coriolis will use during replication/CBT-based migration from VMWare.
      # This value should ideally match the ESXi/vCenter hosts versions.
      vixdisklib_compatibility_version = 6.0
      
      # The path where the SOs for vixDiskLib are located:
      # NOTE: for Ubuntu worker VMs, we must prevent the libglib shipped with
      # vixDiskLib to override the system's libglib by prepending the system's
      # library paths (for 16.04 and 18.04, respectively):
      vixdisklib_library_directory = /lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:{{ coriolis_vmware_vix_disklib_dir }}
      
      # Whether or not Coriolis should attempt to automatically enable CBT on
      # the VM before Replication.
      # This requires that the VM have no pre-existing snapshots.
      automatically_enable_cbt = False
  logging:
    loggers:
      keys:
        - root
        - coriolis
    handlers:
      keys:
        - stdout
        - stderr
        - "null"
    formatters:
      keys:
        - context
        - default
    logger_root:
      level: WARNING
      handlers: stdout
    logger_coriolis:
      level: DEBUG
      handlers:
        - stdout
      qualname: coriolis
    logger_amqp:
      level: WARNING
      handlers: stderr
      qualname: amqp
    logger_amqplib:
      level: WARNING
      handlers: stderr
      qualname: amqplib
    logger_eventletwsgi:
      level: WARNING
      handlers: stderr
      qualname: eventlet.wsgi.server
    logger_sqlalchemy:
      level: WARNING
      handlers: stderr
      qualname: sqlalchemy
    logger_boto:
      level: WARNING
      handlers: stderr
      qualname: boto
    # TODO: research logging options for coriolis-logger:
    handler_null:
      class: logging.NullHandler
      formatter: default
      args: ()
    handler_stdout:
      class: StreamHandler
      args: (sys.stdout,)
      formatter: context
    handler_stderr:
      class: StreamHandler
      args: (sys.stderr,)
      formatter: context
    formatter_context:
      class: oslo_log.formatters.ContextFormatter
      datefmt: "%Y-%m-%d %H:%M:%S"
    formatter_default:
      format: "%(message)s"
      datefmt: "%Y-%m-%d %H:%M:%S"
  rabbitmq:
    #NOTE(rk760n): adding rmq policy to mirror messages from notification queues and set expiration time for the ones
    policies:
      # TODO: check if these are necessary
      - vhost: "coriolis"
        name: "ha_ttl_coriolis"
        definition:
          #mirror messges to other nodes in rmq cluster
          ha-mode: "all"
          ha-sync-mode: "automatic"
          #70s
          message-ttl: 70000
        priority: 0
        apply-to: all
        pattern: '^(?!(amq\.|reply_)).*'
  # TODO: see what these are for:
  #resource_filters:
  #  volume:
  #    - name
  #    - status
  #    - metadata
  #    - bootable
  #    - migration_status
  #    - availability_zone
  #    - group_id
  #  backup:
  #    - name
  #    - status
  #    - volume_id
  #  snapshot:
  #    - name
  #    - status
  #    - volume_id
  #    - metadata
  #    - availability_zone

dependencies:
  dynamic:
    common:
      local_image_registry:
        jobs:
          - coriolis-image-repo-sync
        services:
          - endpoint: node
            service: local_image_registry
  static:
    api:
      jobs:
        - coriolis-db-sync
        - coriolis-ks-user
        - coriolis-ks-endpoints
        - coriolis-rabbit-init
      services:
        - endpoint: internal
          service: oslo_db
        # NOTE: required for auth:
        - endpoint: internal
          service: identity
    conductor:
      jobs:
        - coriolis-db-sync
        - coriolis-ks-user
        - coriolis-ks-endpoints
        - coriolis-rabbit-init
      services:
        - endpoint: internal
          service: oslo_db
        # NOTE: required for auth and checks:
        - endpoint: internal
          service: identity
    replica_cron:
      jobs:
        - coriolis-db-sync
        - coriolis-ks-user
        - coriolis-ks-endpoints
        - coriolis-rabbit-init
      services:
        - endpoint: internal
          service: oslo_db
        # TODO: check if required:
        - endpoint: internal
          service: identity
    worker:
      jobs:
        - coriolis-db-sync
        - coriolis-ks-user
        - coriolis-ks-endpoints
        - coriolis-rabbit-init
      services:
        - endpoint: internal
          service: oslo_db
        # NOTE: required for fetching Barbican secrets:
        - endpoint: internal
          service: identity
    bootstrap:
      services:
        - endpoint: internal
          service: identity
        - endpoint: internal
          service: volume
      pod:
        - requireSameNode: false
          labels:
            # NOTE: see what this reference points to:
            application: coriolis
            component: volume
    clean:
      jobs: null
    db_drop:
      services:
        - endpoint: internal
          service: oslo_db
    db_init:
      services:
        - endpoint: internal
          service: oslo_db
    db_sync:
      jobs:
        # TODO: define:
        - coriolis-db-init
      services:
        - endpoint: internal
          service: oslo_db
    ks_endpoints:
      jobs:
        # TODO: define:
        - coriolis-ks-service
      services:
        - endpoint: internal
          service: identity
    ks_service:
      services:
        - endpoint: internal
          service: identity
    ks_user:
      services:
        - endpoint: internal
          service: identity
    rabbit_init:
      services:
        - service: oslo_messaging
          endpoint: internal
    # TODO: check if required:
    image_repo_sync:
      services:
        - endpoint: internal
          service: local_image_registry
    create_internal_tenant:
      services:
        - endpoint: internal
          service: identity

# Names of secrets used by bootstrap and environmental checks:
secrets:
  identity:
    admin: coriolis-keystone-admin
    coriolis: coriolis-keystone-user
  oslo_db:
    admin: coriolis-db-admin
    coriolis: coriolis-db-user
  oslo_messaging:
    admin: coriolis-rabbitmq-admin
    coriolis: coriolis-rabbitmq-user
  tls:
    migration:
      api:
        public: coriolis-tls-public

# We use a different layout of the endpoints here to account for versioning
# this swaps the service name and type, and should be rolled out to other
# services.
endpoints:

  # TODO: add web-proxy?

  cluster_domain_suffix: cluster.local

  local_image_registry:
    name: docker-registry
    namespace: docker-registry
    hosts:
      default: localhost
      internal: docker-registry
      node: localhost
    host_fqdn_override:
      default: null
    port:
      registry:
        # TODO: add registry.cloudbase.it port too:
        node: 5000

  identity:
    name: keystone
    auth:
      admin:
        region_name: RegionOne
        username: admin
        password: password
        project_name: admin
        user_domain_name: default
        project_domain_name: default
      coriolis:
        role: admin
        region_name: RegionOne
        username: coriolis
        password: password
        project_name: service
        user_domain_name: service
        project_domain_name: service
    hosts:
      default: keystone
      internal: keystone-api
    host_fqdn_override:
      default: null
    path:
      default: /v3
    scheme:
      default: http
    port:
      api:
        default: 80
        internal: 5000
  migration:
    name: coriolis
    hosts:
      default: coriolis-api
      public: coriolis
    host_fqdn_override:
      default: null
      # NOTE(portdirect): this chart supports TLS for fqdn over-ridden public
      # endpoints using the following format:
      # public:
      #   host: null
      #   tls:
      #     crt: null
      #     key: null
    path:
      default: '/v1/%(tenant_id)s'
    scheme:
      default: 'http'
    port:
      api:
        default: 7667
        public: 80
  oslo_db:
    auth:
      # TODO: check where these are set/used and use them:
      admin:
        username: root
        password: password
      coriolis:
        username: coriolis
        password: password
    hosts:
      default: mariadb
    host_fqdn_override:
      default: null
    path: /coriolis
    scheme: mysql+pymysql
    port:
      mysql:
        default: 3306
  oslo_messaging:
    auth:
      # TODO: check where these are set/used and use them:
      admin:
        username: rabbitmq
        password: password
      coriolis:
        username: coriolis
        password: password
    statefulset:
      replicas: 2
      name: rabbitmq-rabbitmq
    hosts:
      default: rabbitmq
    host_fqdn_override:
      default: null
    path: /coriolis
    scheme: rabbit
    port:
      amqp:
        default: 5672
      http:
        default: 15672
  # TODO: see how/where to set these:
  oslo_cache:
    auth:
      # NOTE(portdirect): this is used to define the value for keystone
      # authtoken cache encryption key, if not set it will be populated
      # automatically with a random value, but to take advantage of
      # this feature all services should be set to use the same key,
      # and memcache service.
      memcache_secret_key: null
    hosts:
      default: memcached
    host_fqdn_override:
      default: null
    port:
      memcache:
        default: 11211
  kube_dns:
    namespace: kube-system
    name: kubernetes-dns
    hosts:
      default: kube-dns
    host_fqdn_override:
      default: null
    path:
      default: null
    scheme: http
    port:
      dns:
        default: 53
        protocol: UDP
  ingress:
    namespace: null
    name: ingress
    hosts:
      default: ingress
    port:
      ingress:
        default: 80

network_policy:
  coriolis:
    ingress:
      - {}
    egress:
      - {}

manifests:
  configmap_bin: true
  configmap_etc: true

  deployment_api: true
  deployment_conductor: true
  deployment_replica_cron: true
  deployment_worker: true

  # TODO: enable web UI:
  deployment_web: false
  deployment_web_proxy: false

  ingress_api: true
  job_bootstrap: true
  job_clean: true
  job_create_internal_tenant: true
  job_db_init: true
  job_rabbit_init: true
  job_db_sync: true
  job_db_drop: true
  job_ks_endpoints: true
  job_ks_service: true
  job_ks_user: true
  job_storage_init: true

  #pdb_api: true
  #pod_rally_test: true
  #pvc_backup: true
  #network_policy: false

  secret_db: true
  secret_ingress_tls: true
  secret_keystone: true
  secret_rabbitmq: true

  service_api: true
  service_ingress_api: true

########### auto-generated by `helm create`:
# replicaCount: 1

#image:
#  repository: nginx
#  pullPolicy: IfNotPresent

#imagePullSecrets: []
#nameOverride: ""
#fullnameOverride: ""

#serviceAccount:
#  # Specifies whether a service account should be created
#  create: true
#  # Annotations to add to the service account
#  annotations: {}
#  # The name of the service account to use.
#  # If not set and create is true, a name is generated using the fullname template
#  name:

#podSecurityContext: {}
#  # fsGroup: 2000

#securityContext: {}
#  # capabilities:
#  #   drop:
#  #   - ALL
#  # readOnlyRootFilesystem: true
#  # runAsNonRoot: true
#  # runAsUser: 1000

#service:
#  type: ClusterIP
#  port: 80

#ingress:
#  enabled: false
#  annotations: {}
#    # kubernetes.io/ingress.class: nginx
#    # kubernetes.io/tls-acme: "true"
#  hosts:
#    - host: chart-example.local
#      paths: []
#  tls: []
#  #  - secretName: chart-example-tls
#  #    hosts:
#  #      - chart-example.local

#resources: {}
#  # We usually recommend not to specify default resources and to leave this as a conscious
#  # choice for the user. This also increases chances charts run on environments with little
#  # resources, such as Minikube. If you do want to specify resources, uncomment the following
#  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
#  # limits:
#  #   cpu: 100m
#  #   memory: 128Mi
#  # requests:
#  #   cpu: 100m
#  #   memory: 128Mi

#nodeSelector: {}

#tolerations: []

#affinity: {}
